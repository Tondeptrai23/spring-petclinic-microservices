spring:
  main:
    web-application-type: reactive
  application:
    name: genai-service
  profiles:
    active: production
  config:
    import: optional:configserver:${CONFIG_SERVER_URL:http://localhost:8888/},optional:classpath:/creds.yaml
  ai:
    chat:
      client:
        enabled: true
    # These apply when using spring-ai-azure-openai-spring-boot-starter
    azure:
      openai:
        api-key: ${AZURE_OPENAI_KEY}
        endpoint: ${AZURE_OPENAI_ENDPOINT}
        chat:
          options:
            temperature: 0.7
            deployment-name: gpt-4o
    # These apply when using spring-ai-openai-spring-boot-starter
    openai:
      api-key: ${OPENAI_API_KEY:demo}
      chat:
        options:
            temperature: 0.7
            model: gpt-4o-mini


logging:
  level:
    org:
      springframework:
        ai:
          chat:
            client:
              advisor: DEBUG
---
spring:
  config:
    activate:
      on-profile: docker
    import: configserver:http://config-server:8888

---
management:
  endpoints:
    web:
      exposure:
        include: prometheus
  endpoint:
    health:
      show-details: always
  tracing:
    enabled: ${MANAGEMENT_TRACING_ENABLED:true}
    sampling:
      probability: ${MANAGEMENT_TRACING_SAMPLING_PROBABILITY:1.0}
  zipkin:
    tracing:
      enabled: ${MANAGEMENT_ZIPKIN_TRACING_ENABLED:true}
      endpoint: ${MANAGEMENT_ZIPKIN_TRACING_ENDPOINT:http://zipkin:9411/api/v2/spans}

logging:
  pattern:
    level: ${LOGGING_PATTERN_LEVEL:%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]}
  level:
    org:
      springframework:
        ai:
          chat:
            client:
              advisor: DEBUG
    io.micrometer.tracing: ${LOGGING_LEVEL_IO_MICROMETER_TRACING:DEBUG}